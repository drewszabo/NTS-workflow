---
title: "NTS Workshop - YES Meeting (SETAC)"
author: "Drew Szabo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
---

# Introduction

This workshop demonstrates a non-targeted screening (NTS) workflow using high-resolution mass spectrometry (HRMS) data and open-source tools in R. We will follow the method developed in [this publication](https://doi.org/10.1021/acs.analchem.4c02041) and updated in [this GitHub repository](https://github.com/drewszabo/NTS-workflow) by Drew Szabo. This workflow is based on the [patRoon](https://rickhelmus.github.io/patRoon/) platform, which is open-access and open-source to provide the most control over your data. This workflow is ideal for research but is not necessarily aimed towards high-throughput commercial applications.

## Objectives

- Introduction to NTS workflow and its major components.
- Demonstration of feature finding, including peak picking, retention time alignment, and grouping (`xcms`).
- Perform basic thresholding, and componentisation (`CAMERA`).
- Perform formula generation and compound annotation (`MassBank`, `SIRIUS`).
- Demonstrate suspect screening against a list of pharmaceuticals (`patRoon`).
- Perform acute aquatic toxicity prediction (`MS2Tox`).
- Export data for feature-based molecular networking FBMN (`GNPS`).

## Who is this for?

This workshop is designed for researchers with a basic understanding of R and high-resolution mass spectrometry. Some sections include advanced concepts or tools, but we will explain each step as we go. You donâ€™t need prior experience with patRoon or XCMS.

## Required Files

We'll use a small demonstration dataset provided in the GitHub repository. Please download files from [this GitHub repo](https://github.com/drewszabo/NTS-workflow) before starting the workshop.

---

## Third Party Accounts (required)

To use some third-party software, registration is required to acquire a non-commercial licence. Please use the following links to create an account using your institution email. This should be automatically recognised as an academic source and grant immediate access.

SIRIUS CSI:FingerID: [Register Here](https://portal.bright-giant.com/auth/login).

GNPS: [Register Here](https://gnps.ucsd.edu/ProteoSAFe/user/register.jsp)

Additionally, please read the licence agreement from ProteoWizard [here](https://proteowizard.sourceforge.io/licenses.html)

---

# 1. Setup and Initialisation

## 1.1 Installation

Note: This should have already been completed for this workshop. Skip to the next chunk to verify the dependencies.

Install the latest version of patRoon from [GitHub](https://www.github.com/rickhelmus/patRoon). For troubleshooting, please visit [the documentation](https://rickhelmus.github.io/patRoon/handbook_bd/reg_inst.html#auto_inst)

```{r install, include=TRUE, eval=FALSE}
# Load patRoon install library
remotes::install_github("rickhelmus/patRoonInst")

# Run the installation function
patRoonInst::install()
patRoonInst::update()
```

Check that each third-party dependency has been found, and use the `options()` function to manually set paths.

```{r verify, include=TRUE}
# Check that all third-party tools are correctly installed
patRoon::verifyDependencies()

# If a dependency is missing, you can manually set the path like this:
options(patRoon.path.SIRIUS = "C:/Program Files/sirius/")
```

## 1.2 Setup

Load (install if necessary) the latest versions of the other patRoon dependencies. Note: only load `tidyverse` when necessary as it shares functions with patRoon that can cause errors I.E. `select()` and `filter()`

```{r library, include=TRUE, message=FALSE, warning=FALSE}
# Load dependancies
library(patRoon)
library(MSnbase) # install.packages("BiocManager")
library(xcms) # BiocManager::install("xcms")
library(CAMERA) # BiocManager::install("CAMERA")
library(MS2Tox) # remotes::install_github("kruvelab/MS2Tox")
library(rJava)
#library(tidyverse)
```

Set some extra configurations to make the process smoother.

```{r config, include=TRUE}
# Increase default Java memory
options(java.parameters = "-Xmx32g") # 32GB RAM adjust as needed

# Limit patRoon processes to increase stability
options(patRoon.MP.maxProcs = 4)

# Deactivate parallel processing in XCMS and others to improve stability in Windows
register(SerialParam())

# Load some of my custom scripts that will be used to export and import data for processing with third-party software
source("https://raw.githubusercontent.com/drewszabo/NTS-workflow/refs/heads/main/nts_tools.R")

# Load some other custom scripts for additional processing
source("https://raw.githubusercontent.com/jorainer/xcms-gnps-tools/refs/heads/master/customFunctions.R")
```

## 1.3 RAW File Conversion

Using ProteoWizard's msConvert tool, all acquisition files should be converted to .mzML. Additionally, `patRoon` only currently accepts data in the centroid format, so data acquired in profile mode will need to be converted. Thankfully, msConvert can do both at once rather efficiently. This workflow will detail the patRoon code use to perform this conversion, however the GUI program is equally easy to use.

```{r convert, include=TRUE, eval=FALSE}
# Convert vendor RAW files to mzML using ProteoWizard
# - dirs: folder with raw files (relative path)
# - outPath: output folder for converted files
# - from: instrument vendor (e.g., "thermo")
# - centroid: use vendor centroiding if available
# - filters: convert only MS1 and MS2 levels
convertMSFiles(files = "RAW",
               outPath = "mzML",
               from = "thermo",
               to = "mzML",
               centroid = "vendor",
               filters = "msLevel 1-2"
               )
```

## 1.4 Sample Initialisation

You must set the path, file name, and group of each acquisition file to be analysed. Since this information is usually easily accessible from your sequence table, I prepare a CSV to be imported. You should now also include the corresponding blank file for each sample, and the concentration of calibration files if applicable.

For example the path for the files below is: "mzML/sample1-r1.mzML"

Here we will only be using a triplicate sample and corresponding blank. This will reduce the compute time required for this workshop. Although, this will scale to hundreds of samples, which can take several hours or days to complete.

```{r anaInfo, include=TRUE}
# Load metadata for each sample
# anaInfo.csv should include columns like 'file', 'group', and other sample details
anaInfo <- read.csv("anaInfo.csv")
```

```{r kable, echo = FALSE, results = 'asis'}
# Display sample metadata in a formatted table
library(knitr, verbose = FALSE, warn.conflicts = FALSE)
kable(anaInfo)
```

# 2. Feature Finding

## 2.1 Peak Picking

The parameters for the peak picking are defined by the `xcms` [CentWaveParam](https://rdrr.io/bioc/xcms/man/findChromPeaks-centWave.html) documentation. The default parameters are called by using the `xcms::centwaveparam()` function. As a general rule of thumb, I use the average chromatographic peak witdth to calculate the minimum and maximum peak width for extraction. Where min = x/2 and max = 3x. Furthermore, the prefilter and noise level can be defined by looking at the RAW MS1 spectra for a general sample.

The optimal m/z tolerance (`ppm`) and the minimum m/z difference for overlapping peaks (`mzdiff`) can be found by using the `IPO` package - not detailed in this workflow. [See here](https://www.bioconductor.org/packages/release/bioc/html/IPO.html) for more information about IPO. IPO can be used to optimise each parameter, however I have had mixed results with complex samples. Your results may vary.

```{r centwaveparam, include=TRUE}
# Define peak picking parameters for XCMS (CentWave algorithm)
# These were optimized using IPO for Orbitrap data
cwparam <- xcms::CentWaveParam(
  ppm = 8.35,                # Mass accuracy in ppm
  peakwidth = c(5, 30),      # Expected chromatographic peak width range (in seconds)
  snthresh = 15,             # Signal-to-noise threshold
  prefilter = c(3, 1000),    # Minimum # of scans with intensity above threshold
  mzCenterFun = "wMean",     # Method to calculate m/z center of peaks
  integrate = 2,             # Integration method
  fitgauss = TRUE,           # Fit Gaussian curve to peak shape
  mzdiff = -0.007,           # Minimum m/z difference between overlapping peaks
  noise = 1000               # Baseline noise threshold
)
```

Once the parameters are defined, we use the `patRoon` wrapper for the `xcms` algorithm to pick our peaks from each sample. This basically bundles our results in a slightly different format that will remain consistent dispite which other algorithm or program is used. This is one of the main advantages of `patRoon`.

```{r peakpicking, include=TRUE, eval=FALSE}
# Perform peak detection using XCMS with CentWave parameters
# This step detects chromatographic features in each sample
fList <- patRoon::findFeatures(
  anaInfo,
  "xcms3",
  param = cwparam,
  verbose = FALSE
)
```

## 2.2 Grouping and Retention Time Alignment

The parameters for the grouping and retention time alignment are defined by the [PeakDensityParam]() and [ObiWarpParam]() documentation respectively. Again, there are a lot of arguments to optimise to obtain the best results. `IPO` can be used to optimise these parameters. I generally start with mainly the default parameters, then adjust as necessary according to the EIC validation.

```{r groupalignparam, include=TRUE, eval=FALSE}
# Set parameters for feature grouping across samples
pdparam <- xcms::PeakDensityParam(
  sampleGroups = anaInfo$group,
  minFraction = 0,        # Accept features present in any fraction of samples
  minSamples = 1,         # Minimum number of samples a feature must appear in
  bw = 10,                # Bandwidth for retention time grouping
  binSize = 0.05          # Bin size for density estimation
)

# Set retention time alignment parameters using Obiwarp
owparam <- xcms::ObiwarpParam(
  center = 1,             # Use sample 1 as the alignment reference
  response = 1,           # Smoothing response factor
  gapInit = 0.3,          # Penalty for introducing gaps
  gapExtend = 2.4,        # Penalty for extending gaps
  factorDiag = 2,         # Weight for diagonal (match) steps
  factorGap = 1,          # Weight for gap steps
  binSize = 0.5           # RT bin size (used for profile matrix)
)
```

These parameters are wrapped in a patRoon function. The resulting `fGroups` object contains the inital feature list as an `xcms` object.

```{r groupalign, include=TRUE, eval=FALSE}
# Group detected features across all samples with RT alignment
# This creates feature groups that represent the same compound across replicates
fGroups <- groupFeatures(
  fList,
  "xcms3",
  rtalign = TRUE,
  loadRawData = TRUE,     # Load raw data for downstream visualisation or filtering
  groupParam = pdparam,
  retAlignParam = owparam,
  verbose = FALSE
)
```

# 3. Saving & Backup

It's a good idea to regularly save your progress in case of a crash. You can save the environment as a whole, or backup important and timely steps, like the feature finding steps. Some objects will no longer be needed, so it can save lots of time to remove them from the environment before back up. I prefer to work directly off the University network drives, which are secure and redundant. This costs a hit in performance, however it has many advantages for me personally.

Note: patRoon creates a cache file in the working directory `cache.sqlite` that will also store processed data. This is called when you run a repeated function for example. This sometimes comes in handy, however in large runs, this file can reach enormous size (>10GB). I typically delete this from time to time using the `patRoon::clearCache("all")` function, or simply deleting the `cache.sqlite` file in the directory. This will not impact the objects in your environment.

```{r backup, include=TRUE, eval=FALSE}
# Save individual objects
saveRDS(fList, "fList.rds")
saveRDS(fGroups, "fGroups.rds")

# Remove redundant objects from environment to save space and time
rm(fList)

# Backup entire environment (perform regularly)
save.image(".RData") # overwrite existing
save.image(paste0(format(Sys.time(), "%Y-%m-%d_%H:%M"), ".RData")) # timestamped
```

# 4. Thresholding

With a list of all the feautures picked from the samples and blanks, we need to apply some rules to eliminate background contamination and other false positives. Before continuing, it may be a good idea to note the size of the `fGroups` object before filtering. This will give you an idea of the performance of each step.

This is a list of the most useful filters for featureGroups. [Click Here](https://rickhelmus.github.io/patRoon/handbook_bd/filtering.html) for the documentation that lists all arguments in the `patRoon::filter()` function.

```{r thresholding, include=TRUE, eval=FALSE}
# Filter for features that are in all 3 replicates within 80% RSD, and have intensity 3x greater than the blanks.
fGroups <- patRoon::filter(
  fGroups,
  absMinIntensity = 10000, # Minimum intensity
  absMinReplicateAbundance = NULL, # Minimum feature abundance in a replicate group
  relMinReplicateAbundance = 1, # Minimum feature abundance in a replicate group
  relMinReplicates = NULL, # Minimum feature abundance in different replicates
  maxReplicateIntRSD = 0.8, # Maximum relative standard deviation of feature intensities in a replicate group.
  relMinAnalyses = NULL, # Minimum feature abundance in all analyses
  absMinAnalyses = NULL,
  blankThreshold = 3,
  removeBlanks = TRUE
)
```
You should now have 7444 features (elements) in the `fGroups` object.

To view a feature table, including the m/z, rt, and sample abundances, use the `patRoon::as.data.table()` function. Note: since we removed the blanks in the thresholding step, these are not printed in the feature table.

```{r fTable1, include=TRUE, eval=FALSE}
# Create a data.frame containing the feature table
featureTable <- patRoon::as.data.table(
  fGroups,
  area = TRUE, # use the peak area instead of intensity
  average = TRUE # average peak area of all replicates in group
  )
```

# 5. Componentisation

Componentisation with `CAMERA` will look for features that are related to one another. First by applying a rule-table of known mass differences, such as [M+H]+ and [M+Na]+. Then by looking for correlated peak shapes and retention times. This can elucidate potential in-source fragments. This can take some time to process, but this step will be important to performing Ion Identity Molecular Networking (IIMN) later.

```{r componentisation, include=TRUE, eval=FALSE}
# Perform componentisation
components <- generateComponents(fGroups,
                                 "camera",
                                 ionization = "positive")
```

# 6. Peak List Extraction

So far, we only have a list of monoisotopic m/z and rt for a list of features determined by `xcms`. This lacks the information in the MS1 isotopalogue and the MS2 fragmentation. `mzR` is used to extract the MS1 and MS2 peak lists for each feature in our feature table. There are some parameters to be aware of, these have been optimised for my acquisition method - LC-HRMS (Orbitrap). Get more information on these parameters by [clicking here](https://rickhelmus.github.io/patRoon/handbook_bd/annotation.html#ms-peak-lists).

```{r mzRparam, include=TRUE, eval=FALSE}
# Set mzR parameters for peak list extraction
avgFeatParams <- getDefAvgPListParams(clusterMzWindow = 0.005,
                                      topMost = 250
                                      )

# Set patRoon parameters for MS1 peak list filtering
precRules <- getDefIsolatePrecParams(maxIsotopes = 4, # [A+1], [A+2], etc
                                     mzDefectRange = c(-0.1, 0.1) # increase range
                                     )
```

Then simply run the `patRoon` wrapper for `mzR` to apply this to the feature group object.

```{r mzR, include=TRUE, eval=FALSE}
# Perform the MS Peak List extraction
mslists <- generateMSPeakLists(
  fGroups,
  "mzr",
  maxMSRtWindow = 5,
  precursorMzWindow = 0.7,
  topMost = NULL,
  avgFeatParams = avgFeatParams,
  avgFGroupParams = avgFeatParams
)
```

The mslists object can quickly get very large by including all peaks in the MS1 and noisy peaks in the MS2. This is addressed by filtering the peak list.

```{r mzRfilter, include=TRUE, eval=FALSE}
# Filter the peak list to remove unwanted and noisy peaks
mslists <- patRoon::filter(
  mslists,
  absMSIntThr = 1000,
  relMSMSIntThr = 0.01, # filter MS2 peaks within 1% relative abundance
  absMSMSIntThr = 500, # check mzML files
  withMSMS = TRUE, # only keep features with MS2 acquisition
  minMSMSPeaks = 2, # only keep features with at least 2 MS2 peaks
  retainPrecursorMSMS = TRUE,
  isolatePrec = precRules, # apply MS1 filter above
)
```

# 7. Formula and Compound Annotation

## 7.1 Formula Generation

Shout out to `GenForm` which does a great job in predicting formula from HRMS data. But I prefer to use `SIRIUS` for this step, which I already use for my <i>in silico</i> compound annotation in section 7.3. This will generate the same formula as the top ranked candidate in the compound annotation step, which provides a bit more consistency.

There are many parameters to select in this step. For example, I choose to use the "pubchem" library as a reference, however if you are doing metabolomics, the "HMDB" database may be more appropriate. See the [patRoon documentaiton](https://rickhelmus.github.io/patRoon/handbook_bd/annotation.html#formulae) and [SIRIUS documentation](https://v6.docs.sirius-ms.io) for further information.

Note: In order to use the `MS2Tox` and `MS2Quant` packages, only `SIRIUS` v5.x is currently supported. You can download previous versions of `SIRIUS` [here](https://github.com/sirius-ms/sirius/releases)

If you have not already created an account, please do so now with the link above. <u>Do not share your username and password with anyone.</u> Malicious use of your credentials will likely result in a ban.

```{r formSIRIUS, include=TRUE, eval=FALSE}
# Generate formula annotations for each feature using SIRIUS
formulas <- generateFormulas(
  fGroups,
  MSPeakLists = mslists,
  "sirius",
  relMzDev = 5, # MS1 mass error (ppm)
  adduct = "[M+H]+", # only one adduct supported at a time here
  database = "pubchem",
  topMost = 10,
  profile = "orbitrap",
  splitBatches = FALSE,
  cores = 4, # fewer cores has increased stability for me
  elements = "CHONPSFClBr",
  extraOptsFormula = "--ppm-max-ms2=20", # MS2 mass error (ppm) higher due to acquisition parameters
  calculateFeatures = FALSE, # calculate for averaged peak list, rather than individual replicates
  verbose = TRUE,
  login = c(username = "your_username", password = "your_password")
  #login = c(username = Sys.getenv("sirius_user"), password = Sys.getenv("sirius_pass")) # I save my credentials in my .REnviron file to access securely
)
```

As with most steps so far, filtering is required to clean up the returned results. I only keep results that have 2 or more MS2 peaks explained by the model. Here you can also generate a table to start investigating annotated features.

```{r formFilter, include=TRUE, eval=FALSE}
# Filter formulas
formulas <- patRoon::filter(formulas, minExplainedPeaks = 2)

# Generate list of annotations for each feature (max 10 per feature as set above)
formulaTable <- patRoon::as.data.table(formulas)
```

## 7.2 <i>In silico</i> Compound Annotation

Since we just ran the `SIRIUS` formula generation, the same parameters can be used to generate the predicted compound structures.

<i>In silico</i> prediction of compound structure will only allow lower confidence scores compared to spectral library matching (see 7.3). With a decent SIRIUS score of >-50 and with 2 or more explained MS2 peaks, I would typically class this as Level 3b - according to the [Schymanski Scale](https://doi.org/10.1021/es5002105). Conservatively, lower confidence hits I would typically assign to Level 4.

```{r compSIRIUS, include=TRUE, eval=FALSE}
# Generate compound annotations for each feature using SIRIUS
compoundsSIR <-
  generateCompounds(
    fGroups,
    MSPeakLists = mslists,
    "sirius",
    relMzDev = 5,
    adduct = "[M+H]+",
    formulaDatabase = "pubchem",
    topMost = 5,
    topMostFormulas = 10,
    profile = "orbitrap",
    splitBatches = FALSE,
    cores = 4,
    elements = "CHONPSFClBr",
    extraOptsFormula = "--ppm-max-ms2=20",
    verbose = TRUE,
    login = c(username = "your_username", password = "your_password")
  )
```

It is difficult to communicate the annotation of features with more than one compound when presenting this data in a publication or report. For that reason, I choose to only take the <u>top most</u> scored compound by `SIRIUS`. It is important to clearly state this in your methodology, and perform validations with known chemicals spiked into QAQC samples that are included in the data acquisition step. This is not within the scope of this workshop, but you can find more information in my [published workflow](https://doi.org/10.1021/acs.analchem.4c02041).

```{r SIRfilter, include=TRUE, eval=FALSE}
# Filter for minimum explained peaks and formula score
compoundsSIR <- patRoon::filter(compoundsSIR, minExplainedPeaks = 2, topMost = 1)

# View and investigate results
resultsSIR <- patRoon::as.data.table(compoundsSIR, fGroups = fGroups)
```

## 7.3 Spectral Library Annotation

You can use any spectral library that is in the MSP (Mascot Spectral Library) or JSON (JavaScript Object Notation) formats. I usually select the MassBank spectral library since it has very high quality and validated spectrum from users. The metadata associated with MassBank spectrum is also usually fully populated so all the information about the acquisition is easily accessible.

MassBank hits with a cosine similarity >0.9 are considered Level 2a confidence. I consider library hits with cosine similarity between 0.7-0.9 to be Level 3c. You could also load a library from your lab, based on your own reference standards. Here, matches would be considered Level 1.

Download the latest MassBank library (MSP format) from the [GitHub repo](https://github.com/MassBank/MassBank-data/releases). More information on the patRoon spectral library parameters can be found [here](https://rickhelmus.github.io/patRoon/reference/specSimParams.html).

```{r compParam, include=TRUE, eval=FALSE}
# Load MassBank spectral library
massbank <- loadMSLibrary("MassBank_NIST.msp", "msp")

# Increase MS2 mass accuracy to 10 mDa
simParam <- getDefSpecSimParams(
  absMzDev = 0.01
) 
```



```{r compMB, include=TRUE, eval=FALSE}
# Perform spectral library matching to MassBank library
compoundsMB <-
  generateCompounds(
    fGroups,
    MSPeakLists = mslists,
    "library",
    adduct = "[M+H]+",
    MSLibrary = massbank,
    minSim = 0.70,
    absMzDev = 0.01,
    spectrumType = "MS2",
    checkIons = "adduct",
    specSimParams = simParam # increase bin size
  )
```

Finally, filtering matches for the top ranked compound and the compounds with more than 2 MS2 matches increases the confidence in the annotation.

```{r MBfilter, include=TRUE, eval=FALSE}
# Filter top most compounds for minimum explained peaks
compoundsMB <- patRoon::filter(compoundsMB, minExplainedPeaks = 2, topMost = 1)

# Export results for inspection
resultsMB <- patRoon::as.data.table(compoundsMB, fGroups = fGroups)
```

# 8. Offline Prioritization

## 8.1 Suspect Screening

Here I will provide a quick and simple suspect screening approach. patRoon has a built-in function to match the theoretical m/z (and optionally retention time) from a list of SMILES or molecular formula. You can set the adduct argument to common forms like "[M+H]+" and "[M+Na]+". If you would like to do both, you can combine the data frames in a later step.

The suspect screening list selected for this example is from the NORMAN Suspect List Exchange. This is the Swiss list of Pharmaceuticals that also contains consumption data (S10). You can view and download these lists from [here](https://www.norman-network.com/nds/SLE/). We will be doing some basic manipulation of the list, so here is where we should run the `library(tidyverse)` line.

```{r suspScreen, include=TRUE, eval=FALSE}
# Download from the website or optionally download the list using this line
download.file("https://www.norman-network.com/sites/default/files/files/suspectListExchange/031017Update/SwissPharma_TablesS2_CASfix_wDTXSIDs.csv", "SwissPharma_TablesS2_CASfix_wDTXSIDs.csv")

# Load the tidyverse package if not already run
library(tidyverse)

# Read in the csv as a data frame, select just the name and formulas, and inspect the data
suspects <- read.csv("SwissPharma_TablesS2_CASfix_wDTXSIDs.csv") %>%
  dplyr::select(NAME, Molecular_Formula) %>% # Only keep the name and molecular formula columns
  dplyr::rename(name = NAME,
                formula = Molecular_Formula) %>% # reformat the name and formula variables so that patRoon can read it
  dplyr::mutate(name = str_trim(name)) # some names have a space at the end - this will remove the "whitespace"

# Perform the suspect screening
fGroupsSusp <- screenSuspects(fGroups, suspects, adduct = "[M+H]+", mzWindow = 0.002, onlyHits = TRUE)

# Prepare and inspect the results
resultsSusp <- patRoon::as.data.table(fGroupsSusp, area = TRUE, average = TRUE)

# Review and exclude EICs based on their shape and distribution between samples
# Beware: this will take a long time for larger feature groups
checkFeatures(fGroupsSusp, clearSession = TRUE)

# Filter features that you have manually inspected
fGroupsSusp <- patRoon::filter(fGroupsSusp, checkFeaturesSession = "checked-features.yml")

```
### Confidence

Remember that suspect screening, as applied here, has only matched the theoretical m/z with the measured m/z from the feature table. You can include retention time (if known), or predicted retention time (see below) to improve the confidence, but suspect screening by itself is still limited to a Level 4 or Level 5 annotation. Comparison with the retention time, MS1 isotopalogue, the MS2 spectrum, and/or Kendrick Mass Defect must be used for higher confidence annotations.

### Retention Time Prediction

The NORMAN SLE (s0) contains the predicted retention time indices for each compound. This can be used to help exclude features in the wrong retention order. If you have spiked known compounds, or have a range of spiked comopounds in a calibration curve, then you can build a linear regression model to help narrow this time down to a few minutes. Since we do not have any spiked compounds here this is not really possible. But this is a really useful tool for suspect screening.

## 8.2 Toxicity Prediction

This is a really great way to sort and rank all the features acquired with MS2 by order of their predicted aquatic toxicity (LC50) in fish. This model was created and validated by collegues in the [Kruve Lab](https://kruvelab.com) at Stockholm University. For more information on this model, [click here](https://doi.org/10.1021/acs.est.2c02536) to view the published paper. Since we have already perfomed the SIRIUS calculations for identification, we will use those same fingerprints to predict the toxicity.

```{r ms2tox, include=TRUE, eval=FALSE}
# Calculate the predicted toxicity for each feature
compoundsSIR <- predictTox(compoundsSIR, type = "FP", concUnit = "mM")

# Filter feature list to only those with SIRIUS annotation 
fGroupsTox <- patRoon::filter(fGroups, results = compoundsSIR)

# Apply predicted values to
fGroupsTox <- calculateTox(fGroupsTox, compoundsSIR)

# Generate and inspect the results
resultsTox <- patRoon::as.data.table(fGroupsTox, area = TRUE, average = TRUE) %>%
  dplyr::select(group, ret, mz, LC50, LC50_types) %>%
  dplyr::arrange(LC50)

```

This list could be merged with the identification information to then look at the annotated compounds that correspond to these potentially toxic features.

```{r combineTox, include=TRUE, eval=FALSE}
# Join full feature table, with SIRIUS annotations and toxicity predictions.
resultsCombined <- featureTable %>%
  left_join(resultsSIR, by = "group") %>%
  left_join(resultsTox, by = "group")
```

## 8.3 Ion Identity Molecular Networking

Here we will now export all the information that has been generated so far into a format that is compatible with GNPS. GNPS accepts feature tables formatted with `xcms` and `CAMERA`, but since we let `patRoon` handle this previously, we need some extra code to extract that. I have already included a link to these functions in Section 1.2.

This will export a few files to the specified path. There will be a csv containing all the feature information (mandatory), a MGF file containing the corresponding MS1 and MS2 peak lists (mandatory), and finally a csv containing all the "edge" information from `CAMERA` (optional).

```{r gnps, include=TRUE, eval=FALSE}
# Generate GNPS table information from feature list
generateGNPSInfo(fGroups, mslists = mslists, path = "results/")

# Export CAMERA edge list/ feature annotations
iimn <- getEdgelist(components@xsa) %>%
  dplyr::filter(EdgeType == "MS1 annotation")
write.csv(iimn, "results/output_gnps_supp.csv", row.names = FALSE)
```

The next steps will be performed in a web browser and requires a GNPS account. Please visit [http://gnps.ucsd.edu](http://gnps.ucsd.edu) to begin this process. You can also [click here](https://ccms-ucsd.github.io/GNPSDocumentation/fbmn-iin-xcms/) to go to the documentation regarding ion identity molecular networking.

It is also recommended that you use [Cytoscape](https://cytoscape.org) for network visualisations as seen in this example.

This part of the workshop will be demonstrated by Drew at 16:30 and should take approximately 20 minutes. There will be time here to take any final questions.

# Acknowledgements

A big thanks goes out to Rick Helmus, who created the `patRoon` platform. He has been very responsive to issues raised in the GitHub repo. Please report any issues or bugs you have here so that it improves for everyone.

Similarly, to Steffen Neumann and Johannes Rainer and all the other contributors to the `xcms` and `CAMERA` packages. These people are invested in improving these platforms further and keeping them open to the public.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            

